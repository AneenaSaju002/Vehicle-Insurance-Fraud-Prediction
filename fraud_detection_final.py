# -*- coding: utf-8 -*-
"""Fraud_Detection_Final.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1wvXhElBbM2_DB4fUW0b3ofh1bW-3aASo
"""

import pandas as pd
import warnings
import numpy as np
from scipy.stats.mstats import winsorize
import seaborn as sns
import matplotlib.pyplot as plt
from sklearn.preprocessing import LabelEncoder
from sklearn.feature_selection import SelectKBest, f_classif
from sklearn.preprocessing import MinMaxScaler
from sklearn.model_selection import train_test_split
from sklearn.neighbors import KNeighborsClassifier
from sklearn.svm import SVC
from sklearn.naive_bayes import GaussianNB
from sklearn.tree import DecisionTreeClassifier
from sklearn.metrics import classification_report
from sklearn.ensemble import AdaBoostClassifier
from sklearn.ensemble import GradientBoostingClassifier
from xgboost import XGBClassifier
from sklearn.ensemble import RandomForestClassifier
from imblearn.over_sampling import SMOTE
from sklearn.ensemble import StackingClassifier
from imblearn.under_sampling import RandomUnderSampler
from sklearn.model_selection import GridSearchCV
from sklearn.metrics import accuracy_score
from sklearn.metrics import ConfusionMatrixDisplay
from sklearn.metrics import RocCurveDisplay

df=pd.read_csv('/content/drive/MyDrive/fraud_oracle.csv')
df

df.drop(['Age','PolicyNumber','RepNumber'],axis=1,inplace=True)

warnings.filterwarnings('ignore')

"""**DATA CHECK**"""

df.describe()

df.info()

df.isna().sum()

df.duplicated().sum()

df = df.drop_duplicates()

df.duplicated().sum()

pd.set_option('display.max_columns', None)

df.head()

df['AgeOfPolicyHolder'].unique()

df.tail()

df.rename(columns={'FraudFound_P':'Fraud'},inplace=True)

df['Fraud'].value_counts()

df.groupby('Fraud')['Make'].value_counts()

df['Sex'].value_counts()

s=df.groupby('Fraud')['Sex'].value_counts()
s

df.groupby('Fraud')['MaritalStatus'].value_counts()

df.groupby('Fraud')['AccidentArea'].value_counts()

df.groupby('Fraud')['PolicyType'].value_counts()

df.groupby('Fraud')['AgeOfVehicle'].value_counts()

a=df.groupby('Fraud')['AgeOfPolicyHolder'].value_counts()
a

df.groupby('Fraud')['WitnessPresent'].value_counts()

df.groupby('Fraud')['PoliceReportFiled'].value_counts()

df.groupby('Fraud')['VehicleCategory'].value_counts()

"""**EXPLORATORY DATA ANALYSIS**

1_***Fraud detection by sex***
"""

plt.pie(s,labels=s.index,autopct='%.02f')

"""***2_Fraud Detection by VehicleCategory***"""

sns.countplot(df,x='VehicleCategory',hue='Fraud')

"""***3_Fraud Detection by Make***"""

plt.figure(figsize=(18, 6))
sns.countplot(df,x='Make',hue='Fraud')
plt.show()

"""***4_Fraud Detection by age of vehicle and policy holder***"""

plt.figure(figsize=(16, 6))
sns.scatterplot(x="AgeOfVehicle", y="AgeOfPolicyHolder", hue="Fraud", data=df)
plt.show()

"""***5_Fraud Detection by Accident Area***"""

plt.figure(figsize=(12, 6))
sns.countplot(df,x='AccidentArea',hue='Fraud')
plt.show()

"""***6_Fraud Detection by PolicyType***"""

plt.figure(figsize=(12,6))
sns.countplot(x='PolicyType', hue='Fraud', data=df)
plt.xticks(rotation=45, ha='right')
plt.show()

# plt.figure(figsize=(12,6))
# sns.barplot(x='Fraud',y='PolicyType',data=df)
# plt.xticks(rotation=45, ha='right')
# plt.show()

"""***7_Fraud Detection by Vehicle Price***"""

plt.figure(figsize=(12,6))
sns.countplot(x='VehiclePrice', hue='Fraud', data=df)
plt.xticks(rotation=45, ha='right')
plt.show()

"""***8_Fraud Detected by Age & SeX***"""

plt.figure(figsize=(12,6))
sns.violinplot(x='Sex', y='AgeOfPolicyHolder', data=df, hue='Fraud')
plt.show()

"""***9_Relationship  between Numeric features***"""

plt.figure(figsize = (12,8))
sns.heatmap(df.corr(numeric_only=True),annot = True)

"""***10_BoxPlot to identify Outliers***"""

df_numeric = df.select_dtypes(include=['float64', 'int64'])

plt.figure(figsize=(18, 6))
sns.boxplot(data=df_numeric)
plt.xticks(rotation=45)
plt.title("Boxplot of All Numeric Features")
plt.show()

df['Deductible'].value_counts()

"""**DATA PREPROCESSING**

Handling Outliers
"""

plt.figure(figsize=(18, 6))
sns.boxplot(data=df_numeric)
plt.title('Before Winsorization')
plt.show()

df_numeric['Deductible'] = winsorize(df_numeric['Deductible'], limits=[0.04, 0.04])


plt.figure(figsize=(18, 6))
sns.boxplot(data=df_numeric)
plt.title('After Winsorization')
plt.show()

df_non_numeric = df.select_dtypes(exclude=['number'])

df_combined = pd.concat([df_numeric, df_non_numeric], axis=1)

df=df_combined.copy()
df

df['Deductible'].value_counts()

"""*Convert Objects to numeric*"""

df.dtypes

"""Label Encoding"""

cols = ['Month', 'DayOfWeek', 'Make', 'AccidentArea', 'DayOfWeekClaimed', 'MonthClaimed', 'Sex', 'MaritalStatus', 'Fault', 'PolicyType', 'VehicleCategory', 'VehiclePrice', 'Days_Policy_Accident', 'Days_Policy_Claim', 'PastNumberOfClaims', 'AgeOfVehicle', 'AgeOfPolicyHolder', 'PoliceReportFiled', 'WitnessPresent', 'AgentType', 'NumberOfSuppliments', 'AddressChange_Claim', 'NumberOfCars', 'BasePolicy']
encoder=LabelEncoder()
for i in cols:
  encoder.fit(df[i])
  print(encoder.classes_)
  df[i]=encoder.transform(df[i])

df.corr()[['Fraud']].sort_values(by='Fraud',ascending=False)

df.dtypes

"""Input features"""

X=df.drop(['Fraud'],axis=1)
X

"""Label"""

y=df['Fraud']
y

"""Feature Selection"""

df.corr()['Fraud']

from sklearn.feature_selection import SelectKBest, f_classif
selector = SelectKBest(score_func=f_classif, k=14)
X_n = selector.fit_transform(X, y)

selected_features = X.columns[selector.get_support()]
print('Selected Features:', selected_features.tolist())

X_new=df[['Year','Make','AccidentArea','Sex','Fault','PolicyType','VehicleCategory','VehiclePrice','PastNumberOfClaims','AgeOfVehicle','AgeOfPolicyHolder','AgentType','AddressChange_Claim','BasePolicy']]
X_new

"""Scaling"""

scaler=MinMaxScaler()
scaler.fit(X_new)
X_scaled=scaler.transform(X_new)

"""Spliting Data"""

X_train,X_test,y_train,y_test=train_test_split(X_scaled,y,test_size=0.3,random_state=1)

"""MODELS"""

knn=KNeighborsClassifier(n_neighbors=7)
sv=SVC()
nb=GaussianNB()
dt=DecisionTreeClassifier(criterion='entropy',random_state=1,max_depth=9)
models=[knn,sv,nb,dt]
for model in models:
  print(f'**************************{model}*****************************')
  model.fit(X_train,y_train)
  y_pred=model.predict(X_test)
  print(classification_report(y_test,y_pred))
  print(f'Training Accuracy: {round(model.score(X_train, y_train) * 100, 2)}%')
  print(f'Test Accuracy: {round(model.score(X_test, y_test) * 100, 2)}%')

ab=AdaBoostClassifier(random_state=1)
gb=GradientBoostingClassifier(random_state=1)
xb=XGBClassifier(random_state=1)
rf=RandomForestClassifier(random_state=1)
models=[ab,gb,xb,rf]
for model in models:
  print(f'**************************{model}*****************************')
  model.fit(X_train,y_train)
  y_pred=model.predict(X_test)
  print(classification_report(y_test,y_pred))
  print(f'Training Accuracy: {round(model.score(X_train, y_train) * 100, 2)}%')
  print(f'Test Accuracy: {round(model.score(X_test, y_test) * 100, 2)}%')

"""Dataset is an imbalanced dataset. We have to do oversampling/under sampling.

Oversampling
"""

os=SMOTE(random_state=1)
X_train_os,y_train_os=os.fit_resample(X_train,y_train)
X_test_os,y_test_os=os.fit_resample(X_test,y_test)

"""Model After Oversampling"""

knn=KNeighborsClassifier(n_neighbors=7)
sv=SVC()
nb=GaussianNB()
dt=DecisionTreeClassifier(criterion='entropy',random_state=1,max_depth=9)
models=[knn,sv,nb,dt]
for model in models:
  print(f'**************************{model}*****************************')
  model.fit(X_train_os,y_train_os)
  y_pred=model.predict(X_test_os)
  print(classification_report(y_test_os,y_pred))
  print(f'Training Accuracy: {round(model.score(X_train_os, y_train_os) * 100, 2)}%')
  print(f'Test Accuracy: {round(model.score(X_test_os, y_test_os) * 100, 2)}%')

ab=AdaBoostClassifier(random_state=1)
gb=GradientBoostingClassifier(random_state=1)
xb=XGBClassifier(random_state=1)
rf=RandomForestClassifier(random_state=1)
models=[ab,gb,xb,rf]
for model in models:
  print(f'**************************{model}*****************************')
  model.fit(X_train_os,y_train_os)
  y_pred=model.predict(X_test_os)
  print(classification_report(y_test_os,y_pred))
  print(f'Training Accuracy: {round(model.score(X_train_os, y_train_os) * 100, 2)}%')
  print(f'Test Accuracy: {round(model.score(X_test_os, y_test_os) * 100, 2)}%')

"""Stacking_over sampling"""

base_models = [('svm', SVC()),
    ('nb', GaussianNB()),
    ('knn', KNeighborsClassifier(n_neighbors=3)),
    ('dt', DecisionTreeClassifier())]

meta_model = RandomForestClassifier(random_state=1)

stacking= StackingClassifier(estimators=base_models, final_estimator=meta_model)

stacking.fit(X_train_os, y_train_os)

y_pred = stacking.predict(X_test_os)
print(classification_report(y_test_os,y_pred))
print(f'Training Accuracy: {round(model.score(X_train_os, y_train_os) * 100, 2)}%')
print(f'Test Accuracy: {round(model.score(X_test_os, y_test_os) * 100, 2)}%')

"""After oversampling XGBClassifier is a best model with accuracy 95% with 97% of Training accuracy and 94.5% of testing accuracy.

Gradient boosting classifier have same test accuracy and training accuracy which is 93%.

Undersampling
"""

us=RandomUnderSampler(random_state=1)
X_train_us,y_train_us=us.fit_resample(X_train,y_train)
X_test_us,y_test_us=us.fit_resample(X_test,y_test)

"""After undersampling"""

knn=KNeighborsClassifier(n_neighbors=7)
sv=SVC()
nb=GaussianNB()
dt=DecisionTreeClassifier(criterion='entropy',random_state=1,max_depth=9)
models=[knn,sv,nb,dt]
for model in models:
  print(f'**************************{model}*****************************')
  model.fit(X_train_us,y_train_us)
  y_pred=model.predict(X_test_us)
  print(classification_report(y_test_us,y_pred))
  print(f'Training Accuracy: {round(model.score(X_train_os, y_train_os) * 100, 2)}%')
  print(f'Test Accuracy: {round(model.score(X_test_os, y_test_os) * 100, 2)}%')

ab=AdaBoostClassifier(random_state=1)
gb=GradientBoostingClassifier(random_state=1)
xb=XGBClassifier(random_state=1)
rf=RandomForestClassifier(random_state=1)
models=[ab,gb,xb,rf]
for model in models:
  print(f'**************************{model}*****************************')
  model.fit(X_train_us,y_train_us)
  y_pred=model.predict(X_test_us)
  print(classification_report(y_test_us,y_pred))
  print(f'Training Accuracy: {round(model.score(X_train_os, y_train_os) * 100, 2)}%')
  print(f'Test Accuracy: {round(model.score(X_test_os, y_test_os) * 100, 2)}%')

"""stacking_underSampling"""

base_models = [('svm', SVC()),
    ('nb', GaussianNB()),
    ('knn', KNeighborsClassifier(n_neighbors=3)),
    ('dt', DecisionTreeClassifier())]

meta_model = RandomForestClassifier(random_state=1)

stacking= StackingClassifier(estimators=base_models, final_estimator=meta_model)

stacking.fit(X_train_us, y_train_us)

y_pred = stacking.predict(X_test_us)
print(classification_report(y_test_us,y_pred))
print(f'Training Accuracy: {round(model.score(X_train_os, y_train_os) * 100, 2)}%')
print(f'Test Accuracy: {round(model.score(X_test_os, y_test_os) * 100, 2)}%')

"""Oversampled dataset is better than undersampled data.After using undersampled data the Models are overfitted and have low accuracy.

Parameter Tuning for Gradient boosting classifier
"""

# param_grid = {
#     'n_estimators': [100, 200, 300],
#     'learning_rate': [0.01, 0.1, 0.2],
#     'max_depth': [3, 4, 5],
#     'min_samples_split': [2, 3],
#     'min_samples_leaf': [1, 2]}

# gb_clf = GradientBoostingClassifier(random_state=2)

# grid_search = GridSearchCV(
#     estimator=gb_clf,
#     param_grid=param_grid,
#     cv=3,
#     scoring='accuracy')

# grid_search.fit(X_train_os, y_train_os)

# print("Best Parameters:", grid_search.best_params_)

# best_gb_clf = grid_search.best_estimator_
# y_pred = best_gb_clf.predict(X_test_os)
# test_accuracy = accuracy_score(y_test_os, y_pred)
# print("Test Set Accuracy:", test_accuracy)

"""parameters:- learning_rate= 0.2, max_depth= 5, min_samples_leaf= 1, min_samples_split= 3, n_estimators= 200"""

gb1=GradientBoostingClassifier(learning_rate= 0.2, max_depth= 5, min_samples_leaf= 1, min_samples_split= 3, n_estimators= 200)
gb1.fit(X_train_os,y_train_os)
y_pred1=gb1.predict(X_test_os)
print(classification_report(y_test_os,y_pred1))
print(f'Training Accuracy: {round(gb1.score(X_train_os, y_train_os) * 100, 2)}%')
print(f'Test Accuracy: {round(gb1.score(X_test_os, y_test_os) * 100, 2)}%')

"""Parameter tunned GradientBoostingClassifier have 95% accuracy.

Confusion Matrix- Gradient Boosting Classifier
"""

gb=GradientBoostingClassifier(learning_rate= 0.2, max_depth= 5, min_samples_leaf= 1, min_samples_split= 3, n_estimators= 200)
gb.fit(X_train_os,y_train_os)
y_pred=gb.predict(X_test_os)
print(classification_report(y_test_os,y_pred))
print(f'Training Accuracy: {round(gb.score(X_train_os, y_train_os) * 100, 2)}%')
print(f'Test Accuracy: {round(gb.score(X_test_os, y_test_os) * 100, 2)}%')

y_new=gb1.predict(scaler.transform([[0,1,0,1,0,2,2,4,3,2,2,1,4,0]]))
if y_new==0:
  print('Not Fraud')
else:
  print('Fraud')

y_new1=gb1.predict(scaler.transform([[0,3,1,1,0,4,2,5,3,4,2,1,4,1]]))
if y_new1==0:
  print('Not Fraud')
else:
  print('Fraud')

print(ConfusionMatrixDisplay.from_predictions(y_test_os,y_pred1))

"""ROC Curve"""

RocCurveDisplay.from_estimator(gb1, X_test_os, y_test_os)
plt.title('ROC Curve')
plt.show()

import pickle
pickle.dump(gb1,open('gb_model.sav','wb'))
pickle.dump(scaler,open('scaler.sav','wb'))

"""Parameter tuning for XGboost Classifier"""

# param_grid = {
#     'max_depth': [3, 6, 9],
#     'learning_rate': [0.1, 0.01, 0.001],
#     'n_estimators': [100, 200, 300],
#     'colsample_bytree': [0.6, 0.8, 1.0],
#     'gamma': [0, 0.1, 0.2],
#     'subsample': [0.6, 0.8, 1.0]
# }

# grid_search = GridSearchCV(estimator=xg, param_grid=param_grid, cv=3, scoring='accuracy', verbose=1, n_jobs=-1)
# grid_search.fit(X_train_os, y_train_os)

# print("Best parameters found: ", grid_search.best_params_)
# print("Best accuracy found: ", grid_search.best_score_)

"""{'colsample_bytree': 1.0, 'gamma': 0, 'learning_rate': 0.1, 'max_depth': 9, 'n_estimators': 300, 'subsample': 1.0}"""

xgb1 = XGBClassifier(
    colsample_bytree=1.0,
    gamma=0,
    learning_rate=0.1,
    max_depth=9,
    n_estimators=300,
    subsample=1.0
)
xgb1.fit(X_train_os,y_train_os)
y_pred2=xgb1.predict(X_test_os)
print(classification_report(y_test_os,y_pred2))
print(f'Training Accuracy: {round(xgb1.score(X_train_os, y_train_os) * 100, 2)}%')
print(f'Test Accuracy: {round(xgb1.score(X_test_os, y_test_os) * 100, 2)}%')

"""After parameter tuning XGB model have 94% accuracy . So it is better not to consider this tuned model since with default parameters we gets an accuracy of 95%"""

xgb = XGBClassifier()
xgb.fit(X_train_os,y_train_os)
y_pred3=xgb.predict(X_test_os)
print(classification_report(y_test_os,y_pred3))
print(f'Training Accuracy: {round(xgb.score(X_train_os, y_train_os) * 100, 2)}%')
print(f'Test Accuracy: {round(xgb.score(X_test_os, y_test_os) * 100, 2)}%')

"""Confusion Matrix of XGBClassifier"""

print(ConfusionMatrixDisplay.from_predictions(y_test_os,y_pred3))

"""ROC"""

RocCurveDisplay.from_estimator(xgb, X_test_os, y_test_os)
plt.title('ROC Curve')
plt.show()

"""We can conclude that the parameter tunned Gradient boosing classifier and XGBclassifier with its default parameters are the best models with an accuracy of 95%."""